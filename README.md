# Шарнин Никита Сергеевич, задача №2

## 1. Описание проекта

Проект состоит из Docker-контейнеров: kafka-producer, kafka-consumer, spark. Передача сообщений осуществляется между контейнерами. Для контейнеров были выбраны маловесные образы для того, чтобы полученную систему можно было применять в маломощных устройствах.

К сожалению, проект не удалось привести в рабочее состояние именно по причине проблем с image spark. Выбранный контейнер содержит в себе python3.5, что вызывает ошибки при работе с детекторами: YOLOv7, YOLOv7-tiny, CEAM-YOLOv7, YOLOv7-X. Планировалось провести сравнение скорости работы данных архитектур с предобученными на датасете COCO весами и выбрать лучшую по данному показателю. Затем необходимо было бы заняться обучением выбранной модели с целью повышения её точности работы на предоставленном видеопотоке. В нынешнем виде проект осуществляет только получение и кодировку кадров, без применения детектора, с последующим выводом результатов в консоль. 

Была разработана реализация данной системы с применем flask для создания уже аннотированного видеопотока, доступного локально. Но данный интерфейс не тестировался из-за отсутствия графического интерфейса у виртуальных машин. 

Для подсчёта FPS с помощью time.process учитывается время, затраченное на чтение кадра из kafka, открытие его в формате jpg и получение предсказаний детектора. Взятием обратного к полученному значение, посчитаем количество кадров, которые будут обработаны за секунду.

## 2. Сборка проекта

### Для того, чтобы собрать и запустить данный проект необходимо выполнить следующие команды:

1. docker-compose up -d
2. docker-compose exec spark bash
3. cd /app
4. pip install --upgrade pip
5. pip install -r requirements.txt
6. python producer/producer.py & spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5 --jars consumer/kafka-clients-2.2.0.jar --driver-class-path consumer/kafka-clients-2.2.0.jar consumer/consumer.py




